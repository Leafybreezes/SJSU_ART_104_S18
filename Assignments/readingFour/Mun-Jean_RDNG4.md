Jean Mun
Professor A. Blanton- ART 104
February 21, 2018

 	          Reading 4: “Towards a Poetics of Artificial Superintelligence” by Nora N. Khan
            
	This reading by Nora N. Khan addresses realistic approaches to artificial intelligence that is not 
  commonly considered when in discussion about its potential reach in its technological progressions.
  She discusses the significance in being open-minded with one’s personal perception towards the 
  conceptual grasp of what artificial superintelligence really is and what it could impact. Khan 
  explains that, “ASI would only come one step after an artificial general intelligence (AGI), or an 
  AI that models all aspects of human intelligence, is realized. An AGI can do anything a human can, 
  including learn, reason and improve”.  So an artificial superintelligence would exceed the greatest
  human minds that has ever lived on the planet. It is basically storing the entirety of human knowledge
  that was collectively acquired throughout our recorded history. It has the memory and processing ability
  to recall anything that it needs to access. To elaborate further, Khan explains how it is a “near 
  limitless capacity to extract and form meaning from the trillions upon trillions of events and beings 
  and interactions in the known world”. But she does give credit to all potential possibilities by 
  mentioning how it could be this “Seed AI”; meaning that it would be just a few “cognitive steps” ahead.
  However, her further discussions support her argument of how we should not be so close-minded as to 
  dismiss all the other potentialities of its form. Khan references Jackie Wang’s essay, “We Epistolary 
  Aliens”, which was about her disappointment upon her visitation to the UFP Museum and Research Centre. 
  Admirably, she mentioned how boring human imagination can be. Human depictions of the appearance of the 
  unknown is still within our familiar comfort zones. In Wang’s words, “Is this the best we can come up 
  with...We strain to imagine foreignness, but we don’t get very far from what we know”. Wang’s alien,
  “communicates in smells and telepathic song and weeping and chanting and yearning and the sensation of 
  failure and empathic identification and beatitude”. Khan references Wang to highlight the need for a
  creative and imaginative paradigm shift regarding the conceptual perception of artificial intelligence.
  The alien example/reference is a reminder of the curiosities that uncertainty inspires/sparks in human
  beings. Khan perfectly clarifies that, “As speculative models of potential omniscience, omnipotence and 
  supreme consciousness, artificial intelligences are, like aliens, rich poetic devices. They give us a sense
  of what is possible”. It is an encouragement to not dismiss the strange, for the sake of our intellectual 
  progressions. Focusing on a possibility that shakes one’s existence and reality can be frightening, but the 
  world has never been changed by a person who wasn’t afraid to logically question their beliefs. Being willing 
  to face one’s fears of the unfamiliar takes discipline and training. Khan calls it “cognitive exercise and 
  practice” in becoming an open-minded individual. Most people cannot imagine a world where they are not the
  “central intelligence”. People immediately associate it with doomsday films seeing that we have a habit of
  anthropomorphizing what we don’t understand (like aliens). People know it is frightening because the existence
  of an ASI would mean it can “only be tracked or recorded, never controlled”. We immediately consider the 
  possibility of ASI dangerous, but Khan explains how our simplistic depictions of aliens are explanatory of our
  irrational and typical fears of what A.I. could entail. She opposes these irrationalities by speaking of how 
  “her purpose isn’t malign, but it isn’t benevolent either”. It would result in a non-human form/version of 
  efficiency(for the world). The exact approach a ASI could take to achieve their version of this efficiency, 
  is what is uncertain. One of my favorite thought in the reading was when Khan points out that, “Human cognition
  is only one species of intelligence, one with built-in impulses like empathy that colour the way we see the world 
  and limit what we are willing to do to accomplish our goals. But these biochemical impulses aren’t essential 
  components of intelligence. They’re incidental software applications, installed by aeons of evolution and culture”.
  We as the human species, are limited in our nature to accomplish our “goals”. We have all of this stupid and
  unnecessary pain and suffering occurring from the clash of updated and outdated views that slow down efficient
  progressions. We are complex and barbaric in these ways that we cannot come to a logical agreement to prioritize 
  the most efficient strategies to make the world a better place. There is no quick fix with humans due to the 
  discussions that must occur to come to an agreement or compromise. These “biochemical responses” do limit the
  effectiveness of reaching our goals because we cannot quickly come to an agreement when we need to constantly 
  defeat ignorance in every generation before we can proceed. An ASI that can recognize the inefficiencies in our 
  decisions would be very “ruthless” in achieving these goals, likewise to a hurricane that is “strong, yet 
  indifferent”. If there is an AI with a goal to win chess, it will utilize the growing collection of methods for 
  greater accuracy at reaching the goal. This chess example can be considered remarkable because it is a solid 
  example of AI self-progression. But Khan references Bostrom by explaining that chess is “within a limited domain”
  (which is the chessboard). If this “domain” was to be expanded to the real and physical world, it would only make
  sense to be “very specific” about the goals we give our AI.


 “She might have chosen to trawl all the world’s communication for images of efficiency — of armies on the move, of
 gears turning, of highways cut through the mountains.”
